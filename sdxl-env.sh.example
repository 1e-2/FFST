# Reproducible training.
export TRAINING_SEED=420420420

# Restart where we left off. Change this to "checkpoint-1234" to start from a specific checkpoint.
export RESUME_CHECKPOINT="latest"

# How often to checkpoint. Depending on your learning rate, you may wish to change this.

# For the default settings with 10 gradient accumulations, more frequent checkpoints might be preferable at first.
export CHECKPOINTING_STEPS=150
# This is how many checkpoints we will keep. Two is safe, but three is safer.
export CHECKPOINTING_LIMIT=2

export LEARNING_RATE=8e-7 #@param {type:"number"}

# Configure these values.
# Using a Huggingface Hub model:
export MODEL_NAME="stabilityai/stable-diffusion-xl-base-1.0"
# Using a local path to a huggingface hub model or saved checkpoint:
#export MODEL_NAME="/datasets/models/pipeline"

export TRACKER_RUN_NAME="simpletuner-sdxl"

# Use this to append an instance prompt to each caption, used for adding trigger words.
# This has not been tested in SDXL.
#export INSTANCE_PROMPT="lotr style "
# This will be used for WandB uploads.
export VALIDATION_PROMPT="ethnographic photography of teddy bear at a picnic"
# How frequently we will save and run a pipeline for validations.
export VALIDATION_STEPS=100

# Location of training data.
export BASE_DIR="/notebooks/datasets"
export INSTANCE_DIR="${BASE_DIR}/training_data"
export OUTPUT_DIR="${BASE_DIR}/models"

# Some data that we generate will be cached here.
export STATE_PATH="${BASE_DIR}/training_state.json"
# Store whether we've seen an image or not, to prevent repeats.
export SEEN_STATE_PATH="${BASE_DIR}/training_images_seen.json"

# Max number of steps OR epochs can be used. But we default to Epochs.
export MAX_NUM_STEPS=30000
# Will likely overtrain, but that's fine.
export NUM_EPOCHS=25

# Use any standard scheduler type.
export LR_SCHEDULE="constant"
# Whether this is used, depends on whether you have epochs or num_steps in use.
export LR_WARMUP_STEPS=$((MAX_NUM_STEPS / 10))
# Adjust this for your GPU memory size.
export TRAIN_BATCH_SIZE=10

# Leave these alone unless you know what you are doing.
export RESOLUTION=1024
export GRADIENT_ACCUMULATION_STEPS=4          # Yes, it slows training down. No, you don't want to change this.

# SDXL text encoder training is not currently tested.
#export TEXT_ENCODER_LIMIT=101                # Train the text encoder for % of the process. Buggy.
#export TEXT_ENCODER_FREEZE_STRATEGY='before' # before, after, between.
#export TEXT_ENCODER_FREEZE_BEFORE=22         # Ignored when using 'after' strategy.
#export TEXT_ENCODER_FREEZE_AFTER=24          # Ignored when using 'before' strategy.

# Mixed precision is the best. You honestly might need to YOLO it in fp16 mode for Google Colab type setups.
export MIXED_PRECISION="bf16"                # Might not be supported on all GPUs. fp32 will be needed for others.

# With Pytorch 2.1, you might have pretty good luck here.
# If you're using aspect bucketing however, each resolution change will recompile.
export TRAINING_DYNAMO_BACKEND='no'          # or 'inductor' if you want to brave PyTorch 2 compile issues

# This has to be changed if you're training with multiple GPUs.
export TRAINING_NUM_PROCESSES=10
export TRAINING_NUM_MACHINES=1

# These should remain empty if you remove their options.
export ACCELERATE_EXTRA_ARGS="--multi_gpu"                          # --multi_gpu or other similar flags for huggingface accelerate
export DEBUG_EXTRA_ARGS="--print_filenames --report_to=wandb"     # Removing print_filenames can ease on spam.
export TRAINER_EXTRA_ARGS="--allow_tf32 --use_8bit_adam --use_ema"  # anything you want to pass along extra to the actual train_sdxl.py script.

# These are pretty sketchy to change. --use_original_images can be removed to enable image cropping. Not tested for SDXL.
export TRAINER_EXTRA_ARGS="${TRAINER_EXTRA_ARGS} --enable_xformers_memory_efficient_attention --use_original_images=true"
export TRAINER_EXTRA_ARGS="${TRAINER_EXTRA_ARGS} --gradient_checkpointing --gradient_accumulation_steps=${GRADIENT_ACCUMULATION_STEPS}"